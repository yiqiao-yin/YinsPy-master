{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection & Feature Engineering: Predictivity by Influence Score\n",
    "\n",
    "Modern feature selection methodologies such as step-wise backward or forward selection according to AIC/BIC presume a certain underlying model before large dimensions are penalized with an error term. This school of though is problematic because the method left data scientist, statisticians, and machine learning practitioners ensure of the source of impurity of the data set (is error coming from data or the underlying model). \n",
    "\n",
    "Based on this motivation, Professor Shaw-hwa Lo introduced a non-parametric feature selection technique called Influence Score (i.e. I-score). The technique is a function that takes in certain covariates $X$ and dependent variable $y$ and output a measure of how much selected $X$ influences $y$. The formula is derived from the lower bound of Bayes' accuracy. \n",
    "\n",
    "From previous [notebook](https://github.com/yiqiao-yin/YinsPy/blob/master/scripts/python_DS_Measure_Predictivity.ipynb), we have some working knowledge of how Influence Score is computed given selected $X$ and target $y$. This notebook I will build up on what we have done and introduce a generalized feature method. In this book, I cover\n",
    "\n",
    "- **Review: Influence Score** I start by discussing what I covered from influence measure notebook in Data Scructures. We can produce a fixed set of partitions given a covariate matrix $X$. According to these partitions, we can compute the local average of target variable $y$ and calculate how that differs from global average of $y$, i.e. $\\hat{y}$. The discrepancies between local average based on partitions and global average can be raised by the number of observations that fall in each partition. This method, Influence Score, allows us to compute how powerful given (or selected) covariate matrix $X$ is at predicting target variable $y$.\n",
    "\n",
    "- **Backward Dropping Algorithm** Based on upon understanding, we need lots of random sampling to come up with a list of variable modules that are powerful at predicting $y$. This is the place where we design Backward Dropping Algorithm (BDA). The Backward Dropping Algorithm is a greedy searching algorithm that iteratively searching for noisy variables to drop. This system works due to a unique property of Influence Score, e.g. I-score, which is the following. Influence Score of a given collection of covariates increase if there are noisy variables in this collection and they are deleted. Influence Score of a given collection of covariates decrease if there newly added variables that do not contribute to the prediction of target variable.\n",
    "\n",
    "- **Software Development / Product Management** Last, I land on softly coded software products. Then I pack the soft codes in functions using *def* and push all functions into a *class* object in a *.py* script. To reuse this function in the future, I simply need to run the code **%run \"../data/NAME.py\"** in the code box of *ipynb*.\n",
    "\n",
    "- **Application** To test out the product, I reproduce the central idea on a brand new data set: housing price data set. Decision Tree algorithm produced about 89% on out-of-sample test set using original 18 variables. The performance seemed ok, but do we need all 18 variables? I use Influence Score and Backward Dropping Algorithm to screen for potential important variable combinations and I identified two important variables ['sqft_living', 'bedrooms']. By using only 8 variables, I am able to reproduce the 89% out-of-sample test set accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence Score\n",
    "\n",
    "Let us recall the function we coded from previous notebook in the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function\n",
    "def iscore(X, y):\n",
    "    # Environment Initiation\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import random\n",
    "    \n",
    "    # Create Partition\n",
    "    partition = X.iloc[:, 0].astype(str)\n",
    "    if X.shape[1] >= 2:\n",
    "        for i in range(X.shape[1]-1):\n",
    "            partition = partition.astype(str) + '_' + X.iloc[:, i].astype(str)\n",
    "    else:\n",
    "        partition = partition\n",
    "\n",
    "    # Local Information\n",
    "    list_of_partitions = pd.DataFrame(partition.value_counts())\n",
    "    Pi = pd.DataFrame(list_of_partitions.index)\n",
    "    local_n = pd.DataFrame(list_of_partitions.iloc[:, :])\n",
    "\n",
    "    # Compute Influence Score:\n",
    "    import collections\n",
    "    list_local_mean = []\n",
    "    Y_bar = y.mean()\n",
    "    local_mean_vector = []\n",
    "    grouped = pd.DataFrame({'y': y, 'X': partition})\n",
    "    local_mean_vector = pd.DataFrame(grouped.groupby('X').mean())\n",
    "    iscore = np.mean(np.array(local_n).reshape(1, local_n.shape[0]) * np.array((local_mean_vector['y'] - Y_bar)**2))/np.std(y)\n",
    "    \n",
    "    # Output\n",
    "    return {\n",
    "        'X': X,\n",
    "        'y': y,\n",
    "        'Local Mean Vector': local_mean_vector,\n",
    "        'Global Mean': Y_bar,\n",
    "        'Partition': Pi,\n",
    "        'Number of Samples in Partition': local_n,\n",
    "        'Influence Score': iscore}\n",
    "# End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try it on a real data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R&D Spend  Administration  Marketing Spend  Florida  New York\n",
      "0   165349.2       136897.80        471784.10        0         1\n",
      "1   162597.7       151377.59        443898.53        0         0\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "data = pd.read_csv('~/OneDrive/Documents/YinsPy/data/startups_invest.csv')\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, data.shape[1] - 1]\n",
    "y = (y > np.mean(y)).astype(int)\n",
    "State = pd.get_dummies(X.iloc[:, 3], drop_first=True)\n",
    "X = pd.concat([X.iloc[:, :3], State], axis=1)\n",
    "print(X.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R&D Spend  Administration  Marketing Spend  Florida  New York\n",
      "0          1               1                1        0         1\n",
      "1          1               1                1        0         0\n",
      "(50, 5)\n"
     ]
    }
   ],
   "source": [
    "newX = pd.DataFrame([])\n",
    "for j in range(X.shape[1]):\n",
    "    feature = X.iloc[:, j]\n",
    "    feature = (feature > feature.mean()).astype(int)\n",
    "    newX = pd.concat([newX, feature], axis=1)\n",
    "print(newX.head(2))\n",
    "print(newX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Marketing Spend  Florida  Administration\n",
      "0                1        0               1\n",
      "1                1        0               1\n",
      "2                1        1               0\n"
     ]
    }
   ],
   "source": [
    "# Random Sampling\n",
    "# Note: Python executes each code box independently. Once this box is executed\n",
    "#       you have to start from previous code box to recover the original \n",
    "#       covariate matrix first. If this is not done, the covariate matrix \n",
    "#       *newX* will get smaller and smaller.\n",
    "num_initial_draw = 3\n",
    "newX = newX.iloc[:, random.sample(range(newX.shape[1]), num_initial_draw)]\n",
    "print(newX.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0\n",
      "0  0_0_0\n",
      "1  1_1_0\n",
      "2  1_1_1\n",
      "3  0_0_1\n",
      "   Marketing Spend  Florida  Administration\n",
      "0                1        0               1\n",
      "1                1        0               1\n",
      "2                1        1               0\n",
      "3.4715736175130565\n"
     ]
    }
   ],
   "source": [
    "# Try\n",
    "testresult = iscore(X=newX, y=y)\n",
    "print(testresult['Partition'])\n",
    "print(testresult['X'].head(3))\n",
    "print(testresult['Influence Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Backward Dropping Algorithm\n",
    "\n",
    "Let us introduce a greedy backward selection algorithm based on the unique property of Influence Score (i.e. I-score). If selected covariate $X$ carries crucial information about dependent variable $y$, we expect to observe a high value for Influence Score (i.e. I-score). If somehow selected covariate $X$ carries noisy variables that damage the purity of $X$ to predict $y$, we expect this measure to decrease. In addition, the more noisy variable selected covariate matrix carries, the lower the Influence Score (e.g. I-score). Hence, due to this property, we develop the Backward Dropping Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R&D Spend  Administration  Marketing Spend  Florida  New York\n",
      "0          1               1                1        0         1\n",
      "1          1               1                1        0         0\n",
      "(50, 5)\n",
      "   Florida  Marketing Spend  New York  Administration\n",
      "0        0                1         1               1\n",
      "1        0                1         0               1\n",
      "2        1                1         0               0\n"
     ]
    }
   ],
   "source": [
    "newX = pd.DataFrame([])\n",
    "for j in range(X.shape[1]):\n",
    "    feature = X.iloc[:, j]\n",
    "    feature = (feature > feature.mean()).astype(int)\n",
    "    newX = pd.concat([newX, feature], axis=1)\n",
    "print(newX.head(2))\n",
    "print(newX.shape)\n",
    "\n",
    "# Random Sampling\n",
    "# Note: Python executes each code box independently. Once this box is executed\n",
    "#       you have to start from previous code box to recover the original \n",
    "#       covariate matrix first. If this is not done, the covariate matrix \n",
    "#       *newX* will get smaller and smaller.\n",
    "num_initial_draw = 4\n",
    "newX = newX.iloc[:, random.sample(range(newX.shape[1]), num_initial_draw)]\n",
    "print(newX.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.509702801563019\n"
     ]
    }
   ],
   "source": [
    "# Compute Influence Score, e.g. I-score\n",
    "testresult = iscore(X=newX, y=y)\n",
    "print(testresult['Influence Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "newX_copy = newX\n",
    "iscorePath = []\n",
    "selectedX = {}\n",
    "for j in range(newX_copy.shape[1]-1):\n",
    "    unit_scores = []\n",
    "    for i in range(newX.shape[1]):\n",
    "        unit_scores.append(iscore(X=newX.iloc[:, :].drop([str(newX.columns[i])], axis=1), y=y)['Influence Score'])\n",
    "        #print(i, unit_scores, np.max(unit_scores), unit_scores.index(max(unit_scores)))\n",
    "    iscorePath.append(np.max(unit_scores))\n",
    "    to_drop = unit_scores.index(max(unit_scores))\n",
    "    newX = newX.iloc[:, :].drop([str(newX.columns[to_drop])], axis=1).head(3)\n",
    "    selectedX[str(j)] = newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.4939020912464986, 2.0447423868476524, 2.0447423868476524]\n",
      "   Florida  Marketing Spend  Administration\n",
      "0        0                1               1\n",
      "1        0                1               1\n",
      "2        1                1               0\n"
     ]
    }
   ],
   "source": [
    "print(iscorePath)\n",
    "print(selectedX[str(iscorePath.index(max(iscorePath)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software Development / Product Managmeent\n",
    "\n",
    "### Soft Code\n",
    "\n",
    "Let us soft code the procedure of Backward Dropping Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function\n",
    "def FSFE_BDA(newX, y, num_initial_draw = 4):\n",
    "    # Random Sampling\n",
    "    newX = newX.iloc[:, random.sample(range(newX.shape[1]), num_initial_draw)]\n",
    "    \n",
    "    # BDA\n",
    "    newX_copy = newX\n",
    "    iscorePath = []\n",
    "    selectedX = {}\n",
    "    for j in range(newX_copy.shape[1]-1):\n",
    "        unit_scores = []\n",
    "        for i in range(newX.shape[1]):\n",
    "            unit_scores.append(iscore(X=newX.iloc[:, :].drop([str(newX.columns[i])], axis=1), y=y)['Influence Score'])\n",
    "            #print(i, unit_scores, np.max(unit_scores), unit_scores.index(max(unit_scores)))\n",
    "        iscorePath.append(np.max(unit_scores))\n",
    "        to_drop = unit_scores.index(max(unit_scores))\n",
    "        newX = newX.iloc[:, :].drop([str(newX.columns[to_drop])], axis=1).head(3)\n",
    "        selectedX[str(j)] = newX\n",
    "        \n",
    "    # Final Output\n",
    "    finalX = pd.DataFrame(selectedX[str(iscorePath.index(max(iscorePath)))])\n",
    "\n",
    "    # Output\n",
    "    return {\n",
    "        'Path': iscorePath,\n",
    "        'MaxIscore': np.max(iscorePath),\n",
    "        'newX': finalX\n",
    "    }\n",
    "# End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R&D Spend  Administration  Marketing Spend  Florida  New York\n",
      "0   165349.2       136897.80        471784.10        0         1\n",
      "1   162597.7       151377.59        443898.53        0         0\n",
      "   R&D Spend  Administration  Marketing Spend  Florida  New York\n",
      "0          1               1                1        0         1\n",
      "1          1               1                1        0         0\n",
      "(50, 5)\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "data = pd.read_csv('~/OneDrive/Documents/YinsPy/data/startups_invest.csv')\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, data.shape[1] - 1]\n",
    "y = (y > np.mean(y)).astype(int)\n",
    "State = pd.get_dummies(X.iloc[:, 3], drop_first=True)\n",
    "X = pd.concat([X.iloc[:, :3], State], axis=1)\n",
    "print(X.head(2))\n",
    "\n",
    "newX = pd.DataFrame([])\n",
    "for j in range(X.shape[1]):\n",
    "    feature = X.iloc[:, j]\n",
    "    feature = (feature > feature.mean()).astype(int)\n",
    "    newX = pd.concat([newX, feature], axis=1)\n",
    "print(newX.head(2))\n",
    "print(newX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testBDA = FSFE_BDA(newX, y, num_initial_draw = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.544159627264301, 2.0447423868476524, 2.0447423868476524]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testBDA['Path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.544159627264301"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testBDA['MaxIscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Florida</th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>New York</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Florida  R&D Spend  New York\n",
       "0        0          1         1\n",
       "1        0          1         0\n",
       "2        1          1         0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testBDA['newX'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionBasedLearning:\n",
    "\n",
    "    # Define function\n",
    "    def iscore(X, y):\n",
    "        # Environment Initiation\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        import pandas as pd\n",
    "        import random\n",
    "\n",
    "        # Create Partition\n",
    "        partition = X.iloc[:, 0].astype(str)\n",
    "        if X.shape[1] >= 2:\n",
    "            for i in range(X.shape[1]-1):\n",
    "                partition = partition.astype(str) + '_' + X.iloc[:, i].astype(str)\n",
    "        else:\n",
    "            partition = partition\n",
    "\n",
    "        # Local Information\n",
    "        list_of_partitions = pd.DataFrame(partition.value_counts())\n",
    "        Pi = pd.DataFrame(list_of_partitions.index)\n",
    "        local_n = pd.DataFrame(list_of_partitions.iloc[:, :])\n",
    "\n",
    "        # Compute Influence Score:\n",
    "        import collections\n",
    "        list_local_mean = []\n",
    "        Y_bar = y.mean()\n",
    "        local_mean_vector = []\n",
    "        grouped = pd.DataFrame({'y': y, 'X': partition})\n",
    "        local_mean_vector = pd.DataFrame(grouped.groupby('X').mean())\n",
    "        iscore = np.mean(np.array(local_n).reshape(1, local_n.shape[0]) * np.array((local_mean_vector['y'] - Y_bar)**2))/np.std(y)\n",
    "\n",
    "        # Output\n",
    "        return {\n",
    "            'X': X,\n",
    "            'y': y,\n",
    "            'Local Mean Vector': local_mean_vector,\n",
    "            'Global Mean': Y_bar,\n",
    "            'Partition': Pi,\n",
    "            'Number of Samples in Partition': local_n,\n",
    "            'Influence Score': iscore}\n",
    "    # End of function\n",
    "    \n",
    "    # Define function\n",
    "    def FSFE_BDA(newX, y, num_initial_draw = 4):\n",
    "        # Random Sampling\n",
    "        newX = newX.iloc[:, random.sample(range(newX.shape[1]), num_initial_draw)]\n",
    "\n",
    "        # BDA\n",
    "        newX_copy = newX\n",
    "        iscorePath = []\n",
    "        selectedX = {}\n",
    "        for j in range(newX_copy.shape[1]-1):\n",
    "            unit_scores = []\n",
    "            for i in range(newX.shape[1]):\n",
    "                unit_scores.append(InteractionBasedLearning.iscore(X=newX.iloc[:, :].drop([str(newX.columns[i])], axis=1), y=y)['Influence Score'])\n",
    "                #print(i, unit_scores, np.max(unit_scores), unit_scores.index(max(unit_scores)))\n",
    "            iscorePath.append(np.max(unit_scores))\n",
    "            to_drop = unit_scores.index(max(unit_scores))\n",
    "            newX = newX.iloc[:, :].drop([str(newX.columns[to_drop])], axis=1).head(3)\n",
    "            selectedX[str(j)] = newX\n",
    "\n",
    "        # Final Output\n",
    "        finalX = pd.DataFrame(selectedX[str(iscorePath.index(max(iscorePath)))])\n",
    "\n",
    "        # Output\n",
    "        return {\n",
    "            'Path': iscorePath,\n",
    "            'MaxIscore': np.max(iscorePath),\n",
    "            'newX': finalX\n",
    "        }\n",
    "    # End of function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R&D Spend  Administration  Marketing Spend  Florida  New York\n",
      "0   165349.2       136897.80        471784.10        0         1\n",
      "1   162597.7       151377.59        443898.53        0         0\n",
      "   R&D Spend  Administration  Marketing Spend  Florida  New York\n",
      "0          1               1                1        0         1\n",
      "1          1               1                1        0         0\n",
      "(50, 5)\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "data = pd.read_csv('~/OneDrive/Documents/YinsPy/data/startups_invest.csv')\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, data.shape[1] - 1]\n",
    "y = (y > np.mean(y)).astype(int)\n",
    "State = pd.get_dummies(X.iloc[:, 3], drop_first=True)\n",
    "X = pd.concat([X.iloc[:, :3], State], axis=1)\n",
    "print(X.head(2))\n",
    "\n",
    "newX = pd.DataFrame([])\n",
    "for j in range(X.shape[1]):\n",
    "    feature = X.iloc[:, j]\n",
    "    feature = (feature > feature.mean()).astype(int)\n",
    "    newX = pd.concat([newX, feature], axis=1)\n",
    "print(newX.head(2))\n",
    "print(newX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.InteractionBasedLearning.FSFE_BDA(newX, y, num_initial_draw=4)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InteractionBasedLearning.FSFE_BDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testResult = InteractionBasedLearning.FSFE_BDA(newX=newX, y=y, num_initial_draw=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2895893392164464"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testResult['MaxIscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>New York</th>\n",
       "      <th>Florida</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  New York  Florida\n",
       "0          1               1         1        0\n",
       "1          1               1         0        0\n",
       "2          1               0         0        1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testResult['newX']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application\n",
    "\n",
    "We can also save the above *class* object in a *.py* script so that in the future we can load this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Data\n",
    "house_sales = pd.read_csv('../data/kc_house_data.csv')\n",
    "house_sales.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21613, 21)\n"
     ]
    }
   ],
   "source": [
    "print(house_sales.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  \\\n",
      "0         3       1.00         1180      5650     1.0           0     0   \n",
      "1         3       2.25         2570      7242     2.0           0     0   \n",
      "\n",
      "   condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
      "0          3      7        1180              0      1955             0   \n",
      "1          3      7        2170            400      1951          1991   \n",
      "\n",
      "   zipcode      lat     long  sqft_living15  sqft_lot15  \n",
      "0    98178  47.5112 -122.257           1340        5650  \n",
      "1    98125  47.7210 -122.319           1690        7639  \n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        1\n",
      "4        0\n",
      "        ..\n",
      "21608    0\n",
      "21609    0\n",
      "21610    0\n",
      "21611    0\n",
      "21612    0\n",
      "Name: price, Length: 21613, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Clean Data\n",
    "data = house_sales\n",
    "X = data.iloc[:, :].drop(['id', 'date', 'price'], axis=1)\n",
    "y = (data['price'] > np.mean(data['price'])).astype(int)\n",
    "print(X.head(2))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  \\\n",
      "0         0          0            0         0       0           0     0   \n",
      "1         0          1            1         0       1           0     0   \n",
      "\n",
      "   condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
      "0          0      0           0              0         0             0   \n",
      "1          0      0           1              1         0             1   \n",
      "\n",
      "   zipcode  lat  long  sqft_living15  sqft_lot15  \n",
      "0        1    0     0              0           0  \n",
      "1        1    1     0              0           0  \n",
      "(21613, 18)\n"
     ]
    }
   ],
   "source": [
    "newX = pd.DataFrame([])\n",
    "for j in range(X.shape[1]):\n",
    "    feature = X.iloc[:, j]\n",
    "    feature = (feature > feature.mean()).astype(int)\n",
    "    newX = pd.concat([newX, feature], axis=1)\n",
    "print(newX.head(2))\n",
    "print(newX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.InteractionBasedLearning.FSFE_InteractionLearning(newX, y, test_size=0.3, num_initial_draw=7, total_rounds=10, top_how_many=3, verbatim=True)>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run \"../scripts/InteractionBasedLearning.py\"\n",
    "\n",
    "InteractionBasedLearning.FSFE_InteractionLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 0\n",
      "Finished round 1\n",
      "Finished round 2\n",
      "Finished round 3\n",
      "Finished round 4\n",
      "Finished round 5\n",
      "Finished round 6\n",
      "Finished round 7\n",
      "Finished round 8\n",
      "Finished round 9\n",
      "Finished round 10\n",
      "Finished round 11\n",
      "Finished round 12\n",
      "Finished round 13\n",
      "Finished round 14\n",
      "Finished round 15\n",
      "Finished round 16\n",
      "Finished round 17\n",
      "Finished round 18\n",
      "Finished round 19\n",
      "Finished round 20\n",
      "Finished round 21\n",
      "Finished round 22\n",
      "Finished round 23\n",
      "Finished round 24\n",
      "Finished round 25\n",
      "Finished round 26\n",
      "Finished round 27\n",
      "Finished round 28\n",
      "Finished round 29\n",
      "Time Consumption 132.7936885356903\n"
     ]
    }
   ],
   "source": [
    "oneDraw = InteractionBasedLearning.FSFE_InteractionLearning(\n",
    "    newX=newX, y=y, num_initial_draw=7, total_rounds=30, top_how_many=6, verbatim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['condition' 'waterfront' 'yr_built' 'lat' 'waterfront' 'long'\n",
      " 'sqft_living' 'sqft_lot' 'sqft_living' 'sqft_living' 'long']\n"
     ]
    }
   ],
   "source": [
    "print(np.array(oneDraw['New Features'].columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us random sample many times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above script did the following work and this is how we interpret the results:\n",
    "\n",
    "- The script runs functions loaded from *.py* script and the functions are executed five times. There is a time check in the end that is about 30 seconds.\n",
    "\n",
    "- The function outputs an array of variable modules and an array of influence scores (order matters and the are one-one map). For examplt, the first array from both lists are ['lat', 'waterfront', 'sqft_basement'] and the influence measure is about 1216. This is much higher than ['sqft_above'] and ['bathrooms'] but not as high as ['sqft_living', 'bedrooms'] which has an influence measure of 1228.\n",
    "\n",
    "- We can conclude that to build an explanable machine learning algorithm to predict whether housing price for a particular place is higher than average with the variable module ['sqft_living', 'bedrooms'] it is reasonable to use selected variable modules instead of the entire data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../scripts/YinsML.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       condition  waterfront  yr_built      lat  waterfront     long  \\\n",
      "1468           3           0      1965  47.7224           0 -122.332   \n",
      "15590          3           0      1961  47.7725           0 -122.349   \n",
      "18552          3           0      2005  47.7082           0 -122.104   \n",
      "\n",
      "       sqft_living  sqft_lot  sqft_living  sqft_living     long  \n",
      "1468          1390      7200         1390         1390 -122.332  \n",
      "15590         1450      7316         1450         1450 -122.349  \n",
      "18552         2860      5379         2860         2860 -122.104  \n",
      "      0     1\n",
      "0  3762   337\n",
      "1   372  2013\n",
      "0.8906539173349785\n"
     ]
    }
   ],
   "source": [
    "testResult = YinsML.DecisionTree_Classifier(X_train, X_test, y_train, y_test, maxdepth=10)\n",
    "print(testResult['Data']['X_train'].head(3))\n",
    "print(testResult['Test Result']['confusion_test'])\n",
    "print(testResult['Test Result']['test_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us select import variables and then repeat Decision Tree algorithm.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>lat</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>0</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1180</td>\n",
       "      <td>1180</td>\n",
       "      <td>-122.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1951</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>0</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2570</td>\n",
       "      <td>2570</td>\n",
       "      <td>-122.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>0</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>770</td>\n",
       "      <td>770</td>\n",
       "      <td>-122.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1965</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1960</td>\n",
       "      <td>1960</td>\n",
       "      <td>-122.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>0</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1680</td>\n",
       "      <td>1680</td>\n",
       "      <td>-122.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>0</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>1530</td>\n",
       "      <td>1530</td>\n",
       "      <td>-122.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>0</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2310</td>\n",
       "      <td>2310</td>\n",
       "      <td>-122.362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>0</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>1020</td>\n",
       "      <td>1020</td>\n",
       "      <td>-122.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>0</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>-122.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>0</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>1020</td>\n",
       "      <td>1020</td>\n",
       "      <td>-122.299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       condition  waterfront  yr_built      lat  waterfront     long  \\\n",
       "0              3           0      1955  47.5112           0 -122.257   \n",
       "1              3           0      1951  47.7210           0 -122.319   \n",
       "2              3           0      1933  47.7379           0 -122.233   \n",
       "3              5           0      1965  47.5208           0 -122.393   \n",
       "4              3           0      1987  47.6168           0 -122.045   \n",
       "...          ...         ...       ...      ...         ...      ...   \n",
       "21608          3           0      2009  47.6993           0 -122.346   \n",
       "21609          3           0      2014  47.5107           0 -122.362   \n",
       "21610          3           0      2009  47.5944           0 -122.299   \n",
       "21611          3           0      2004  47.5345           0 -122.069   \n",
       "21612          3           0      2008  47.5941           0 -122.299   \n",
       "\n",
       "       sqft_living  sqft_lot  sqft_living  sqft_living     long  \n",
       "0             1180      5650         1180         1180 -122.257  \n",
       "1             2570      7242         2570         2570 -122.319  \n",
       "2              770     10000          770          770 -122.233  \n",
       "3             1960      5000         1960         1960 -122.393  \n",
       "4             1680      8080         1680         1680 -122.045  \n",
       "...            ...       ...          ...          ...      ...  \n",
       "21608         1530      1131         1530         1530 -122.346  \n",
       "21609         2310      5813         2310         2310 -122.362  \n",
       "21610         1020      1350         1020         1020 -122.299  \n",
       "21611         1600      2388         1600         1600 -122.069  \n",
       "21612         1020      1076         1020         1020 -122.299  \n",
       "\n",
       "[21613 rows x 11 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[np.array(oneDraw['New Features'].columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       condition  waterfront  yr_built      lat  waterfront     long  \\\n",
      "1468           3           0      1965  47.7224           0 -122.332   \n",
      "15590          3           0      1961  47.7725           0 -122.349   \n",
      "18552          3           0      2005  47.7082           0 -122.104   \n",
      "\n",
      "       sqft_living  sqft_lot  sqft_living  sqft_living     long  \n",
      "1468          1390      7200         1390         1390 -122.332  \n",
      "15590         1450      7316         1450         1450 -122.349  \n",
      "18552         2860      5379         2860         2860 -122.104  \n",
      "      0     1\n",
      "0  3775   340\n",
      "1   359  2010\n",
      "0.8921961752004935\n"
     ]
    }
   ],
   "source": [
    "informativeX = X[np.array(oneDraw['New Features'].columns)]\n",
    "X_train, X_test, y_train, y_test = train_test_split(informativeX, y, test_size = 0.3, random_state = 0)\n",
    "testResult = YinsML.DecisionTree_Classifier(X_train, X_test, y_train, y_test, maxdepth=8)\n",
    "print(testResult['Data']['X_train'].head(3))\n",
    "print(testResult['Test Result']['confusion_test'])\n",
    "print(testResult['Test Result']['test_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that accuracy on test set (out-of-sample) on original data set is about 89%. Now that we shrink dimension to only 8 variables and the performance is still 89%. This means that it is very possible the rest of the variables do not generate real values in predicting the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us check out the continuous version of the same data set. What if instead of trying to predict whether a housing price is greater than average house price we directly predict the price of the house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  \\\n",
      "0         3       1.00         1180      5650     1.0           0     0   \n",
      "1         3       2.25         2570      7242     2.0           0     0   \n",
      "\n",
      "   condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
      "0          3      7        1180              0      1955             0   \n",
      "1          3      7        2170            400      1951          1991   \n",
      "\n",
      "   zipcode      lat     long  sqft_living15  sqft_lot15  \n",
      "0    98178  47.5112 -122.257           1340        5650  \n",
      "1    98125  47.7210 -122.319           1690        7639  \n",
      "0        221900.0\n",
      "1        538000.0\n",
      "2        180000.0\n",
      "3        604000.0\n",
      "4        510000.0\n",
      "           ...   \n",
      "21608    360000.0\n",
      "21609    400000.0\n",
      "21610    402101.0\n",
      "21611    400000.0\n",
      "21612    325000.0\n",
      "Name: price, Length: 21613, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Clean Data\n",
    "data = house_sales\n",
    "X = data.iloc[:, :].drop(['id', 'date', 'price'], axis=1)\n",
    "y = data['price']\n",
    "print(X.head(2))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241275.06318044738\n",
      "236787.34293765223\n"
     ]
    }
   ],
   "source": [
    "%run \"../scripts/YinsML.py\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "testRegression = YinsML.DecisionTree_Regressor(X_train, X_test, y_train, y_test, maxdepth = 5)\n",
    "print(testRegression['Test Result']['RMSE_test'])\n",
    "print(testRegression['Train Result']['RMSE_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   condition  waterfront  sqft_basement      lat  waterfront  view  \\\n",
      "0          3           0              0  47.5112           0     0   \n",
      "1          3           0            400  47.7210           0     0   \n",
      "2          3           0              0  47.7379           0     0   \n",
      "\n",
      "   sqft_living  yr_renovated  sqft_living  view  \n",
      "0         1180             0         1180     0  \n",
      "1         2570          1991         2570     0  \n",
      "2          770             0          770     0  \n",
      "246130.19906708502\n",
      "234101.04789547794\n"
     ]
    }
   ],
   "source": [
    "informativeX = X[np.array(oneDraw['New Features'].columns)]\n",
    "X_train, X_test, y_train, y_test = train_test_split(informativeX, y, test_size = 0.3, random_state = 0)\n",
    "print(informativeX.head(3))\n",
    "testRegression = YinsML.DecisionTree_Regressor(X_train, X_test, y_train, y_test, maxdepth = 5)\n",
    "print(testRegression['Test Result']['RMSE_test'])\n",
    "print(testRegression['Train Result']['RMSE_train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From performance of regression problem, it seems like the RMSE is smaller with selected variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
