{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPENCV: AUGMENTED REALITY / VIRTUAL REALITY\n",
    "\n",
    "This is the first AR/VR project. In this project, we are going to build a touchless number pad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "from twilio.rest import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in progress...\n",
      "WARNING:tensorflow:From C:\\Users\\eagle\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\eagle\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.2534 - accuracy: 0.9265\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1025 - accuracy: 0.9697\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0676 - accuracy: 0.9796\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0493 - accuracy: 0.9848\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0363 - accuracy: 0.9894\n",
      "10000/10000 [==============================] - 0s 23us/step\n",
      "Model Accuracy:  0.9803000092506409\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print('Training in progress...')\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype('float') / 255\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype('float') / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('Model Accuracy: ', test_acc)\n",
    "print('Training completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
