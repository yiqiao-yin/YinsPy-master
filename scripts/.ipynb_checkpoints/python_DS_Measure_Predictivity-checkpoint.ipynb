{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structures: Measure Predictivity of Features\n",
    "\n",
    "This section we adopt influence measure developed by Lo (2002, 2009, 2012) to investigate the importance of features of start-up investment profits data set.\n",
    "\n",
    "The notebook has the following steps:\n",
    "- $\\textbf{Environment Initiation}$. I always start with initiating the environment. I import the correct modules, APIs, and libraries that need to be used for this notebook and I set up my data set.\n",
    "\n",
    "- $\\textbf{Data Cleanup}$. Data set cleanup is very important. In real world, not all data are saved properly and it is our duty as a data scientist and machine learning practitioner to ensure that the data is valid and can be processed by machines.\n",
    "\n",
    "- $\\textbf{Measure Predictivity}$ I adopt the influence score developed by Lo et al (2002, 2009, 2012) and it is a function that indicates how predictive a sets of features are on response variable $y$.\n",
    "\n",
    "- $\\textbf{Software Development / Product Management}$. Every data science project has two phases. Phase I is about end-to-end research and select the most optimal machine learning procedure. Phase II is about delivering a software product to consumer and clients so that the python codes can be called and there is no need to redo everything that has already been done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Envrionment Initiation\n",
    "\n",
    "Let us initiate our environment by importing the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup\n",
    "\n",
    "Let us get the data and clean up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/OneDrive/Documents/YinsPy/data/startups_invest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
      "0  165349.20       136897.80        471784.10    New York  192261.83\n",
      "1  162597.70       151377.59        443898.53  California  191792.06\n",
      "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
      "(50, 5)\n"
     ]
    }
   ],
   "source": [
    "print(data.head(3))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R&D Spend  Administration  Marketing Spend       State\n",
      "0  165349.20       136897.80        471784.10    New York\n",
      "1  162597.70       151377.59        443898.53  California\n",
      "2  153441.51       101145.55        407934.54     Florida\n",
      "3  144372.41       118671.85        383199.62    New York\n",
      "4  142107.34        91391.77        366168.42     Florida\n",
      "5  131876.90        99814.71        362861.36    New York\n",
      "6  134615.46       147198.87        127716.82  California\n",
      "7  130298.13       145530.06        323876.68     Florida\n",
      "8  120542.52       148718.95        311613.29    New York\n",
      "9  123334.88       108679.17        304981.62  California\n",
      "0     1\n",
      "1     1\n",
      "2     1\n",
      "3     1\n",
      "4     1\n",
      "5     1\n",
      "6     1\n",
      "7     1\n",
      "8     1\n",
      "9     1\n",
      "10    1\n",
      "11    1\n",
      "12    1\n",
      "13    1\n",
      "14    1\n",
      "15    1\n",
      "16    1\n",
      "17    1\n",
      "18    1\n",
      "19    1\n",
      "20    1\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "25    0\n",
      "26    0\n",
      "27    0\n",
      "28    0\n",
      "29    0\n",
      "30    0\n",
      "31    0\n",
      "32    0\n",
      "33    0\n",
      "34    0\n",
      "35    0\n",
      "36    0\n",
      "37    0\n",
      "38    0\n",
      "39    0\n",
      "40    0\n",
      "41    0\n",
      "42    0\n",
      "43    0\n",
      "44    0\n",
      "45    0\n",
      "46    0\n",
      "47    0\n",
      "48    0\n",
      "49    0\n",
      "Name: Profit, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, data.shape[1] - 1]\n",
    "y = (y > np.mean(y)).astype(int)\n",
    "print(X.head(10))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure Predictivity\n",
    "\n",
    "Let me measure the predictivity of each variable and the predictivity of joint variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "newX = pd.DataFrame()\n",
    "for i in range(X.shape[1]):\n",
    "    newColResult = KBinsDiscretizer(n_bins=2, encode='ordinal', strategy='uniform').fit(np.array(X.iloc[:, 1]).reshape(-1, 1))\n",
    "    newCol = newColResult.transform(np.array(X.iloc[:, 1]).reshape(-1, 1))\n",
    "    newCol = pd.DataFrame(newCol)\n",
    "    newX = pd.concat([newX, newCol], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 4)\n",
      "      0    0    0    0\n",
      "0   1.0  1.0  1.0  1.0\n",
      "1   1.0  1.0  1.0  1.0\n",
      "2   0.0  0.0  0.0  0.0\n",
      "3   1.0  1.0  1.0  1.0\n",
      "4   0.0  0.0  0.0  0.0\n",
      "5   0.0  0.0  0.0  0.0\n",
      "6   1.0  1.0  1.0  1.0\n",
      "7   1.0  1.0  1.0  1.0\n",
      "8   1.0  1.0  1.0  1.0\n",
      "9   0.0  0.0  0.0  0.0\n",
      "10  0.0  0.0  0.0  0.0\n",
      "11  0.0  0.0  0.0  0.0\n",
      "12  1.0  1.0  1.0  1.0\n",
      "13  1.0  1.0  1.0  1.0\n",
      "14  1.0  1.0  1.0  1.0\n",
      "15  1.0  1.0  1.0  1.0\n",
      "16  1.0  1.0  1.0  1.0\n",
      "17  1.0  1.0  1.0  1.0\n",
      "18  0.0  0.0  0.0  0.0\n",
      "19  1.0  1.0  1.0  1.0\n",
      "20  0.0  0.0  0.0  0.0\n",
      "21  1.0  1.0  1.0  1.0\n",
      "22  1.0  1.0  1.0  1.0\n",
      "23  0.0  0.0  0.0  0.0\n",
      "24  0.0  0.0  0.0  0.0\n",
      "25  1.0  1.0  1.0  1.0\n",
      "26  1.0  1.0  1.0  1.0\n",
      "27  1.0  1.0  1.0  1.0\n",
      "28  1.0  1.0  1.0  1.0\n",
      "29  1.0  1.0  1.0  1.0\n",
      "30  0.0  0.0  0.0  0.0\n",
      "31  1.0  1.0  1.0  1.0\n",
      "32  1.0  1.0  1.0  1.0\n",
      "33  0.0  0.0  0.0  0.0\n",
      "34  1.0  1.0  1.0  1.0\n",
      "35  0.0  0.0  0.0  0.0\n",
      "36  1.0  1.0  1.0  1.0\n",
      "37  0.0  0.0  0.0  0.0\n",
      "38  0.0  0.0  0.0  0.0\n",
      "39  0.0  0.0  0.0  0.0\n",
      "40  1.0  1.0  1.0  1.0\n",
      "41  0.0  0.0  0.0  0.0\n",
      "42  0.0  0.0  0.0  0.0\n",
      "43  1.0  1.0  1.0  1.0\n",
      "44  1.0  1.0  1.0  1.0\n",
      "45  1.0  1.0  1.0  1.0\n",
      "46  0.0  0.0  0.0  0.0\n",
      "47  1.0  1.0  1.0  1.0\n",
      "48  0.0  0.0  0.0  0.0\n",
      "49  1.0  1.0  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "print(newX.shape)\n",
    "print(newX.iloc[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "num_initial_draw = 2\n",
    "initial_set = newX.iloc[:, random.sample(range(newX.shape[1]), num_initial_draw)]\n",
    "partition = initial_set.iloc[:, 0].astype(str)\n",
    "if initial_set.shape[1] >= 2:\n",
    "    for i in range(initial_set.shape[1]-1):\n",
    "        partition = partition.astype(str) + '_' + initial_set.iloc[:, i].astype(str)\n",
    "else:\n",
    "    partition = partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0_1.0\n",
      "1    1.0_1.0\n",
      "2    0.0_0.0\n",
      "Name: 0, dtype: object\n",
      "1.0_1.0    30\n",
      "0.0_0.0    20\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(partition.head(3))\n",
    "print(partition.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code gives us partition and their counts for each possible combination in the data set. \n",
    "\n",
    "Next, based on partition we can compute the local average of response variable $y$ and compare that with global average of the resposne variable $y$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0\n",
      "0  1.0_1.0\n",
      "1  0.0_0.0\n",
      "          0\n",
      "1.0_1.0  30\n",
      "0.0_0.0  20\n"
     ]
    }
   ],
   "source": [
    "list_of_partitions = pd.DataFrame(partition.value_counts())\n",
    "Pi = pd.DataFrame(list_of_partitions.index)\n",
    "local_n = pd.DataFrame(list_of_partitions.iloc[:, :])\n",
    "print(Pi)\n",
    "print(local_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005853184266750218\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "list_local_mean = []\n",
    "Y_bar = y.mean()\n",
    "local_mean_vector = []\n",
    "grouped = pd.DataFrame({'y': y, 'X': partition})\n",
    "local_mean_vector = pd.DataFrame(grouped.groupby('X').mean())\n",
    "iscore = np.mean((local_mean_vector['y'] - Y_bar)**2)/np.std(y)\n",
    "print(iscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software Development / Product Management\n",
    "\n",
    "Let us code this into a software product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function\n",
    "def iscore(X=newX, y=y, num_initial_draw = 2):\n",
    "    # Environment Initiation\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import random\n",
    "    \n",
    "    # Create Partition\n",
    "    initial_set = newX.iloc[:, random.sample(range(newX.shape[1]), num_initial_draw)]\n",
    "    partition = initial_set.iloc[:, 0].astype(str)\n",
    "    if initial_set.shape[1] >= 2:\n",
    "        for i in range(initial_set.shape[1]-1):\n",
    "            partition = partition.astype(str) + '_' + initial_set.iloc[:, i].astype(str)\n",
    "    else:\n",
    "        partition = partition\n",
    "\n",
    "    # Local Information\n",
    "    list_of_partitions = pd.DataFrame(partition.value_counts())\n",
    "    Pi = pd.DataFrame(list_of_partitions.index)\n",
    "    local_n = pd.DataFrame(list_of_partitions.iloc[:, :])\n",
    "\n",
    "    # Compute Influence Score:\n",
    "    import collections\n",
    "    list_local_mean = []\n",
    "    Y_bar = y.mean()\n",
    "    local_mean_vector = []\n",
    "    grouped = pd.DataFrame({'y': y, 'X': partition})\n",
    "    local_mean_vector = pd.DataFrame(grouped.groupby('X').mean())\n",
    "    iscore = np.mean((local_mean_vector['y'] - Y_bar)**2)/np.std(y)\n",
    "    \n",
    "    # Output\n",
    "    return {\n",
    "        'X': X,\n",
    "        'Set Drawn': initial_set,\n",
    "        'y': y,\n",
    "        'Local Mean Vector': local_mean_vector,\n",
    "        'Global Mean': Y_bar,\n",
    "        'Partition': Pi,\n",
    "        'Number of Samples in Partition': local_n,\n",
    "        'Influence Score': iscore}\n",
    "# End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is done. Let us try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R&D Spend  Administration  Marketing Spend  Florida  New York\n",
      "0   165349.2       136897.80        471784.10        0         1\n",
      "1   162597.7       151377.59        443898.53        0         0\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "data = pd.read_csv('~/OneDrive/Documents/YinsPy/data/startups_invest.csv')\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, data.shape[1] - 1]\n",
    "y = (y > np.mean(y)).astype(int)\n",
    "State = pd.get_dummies(X.iloc[:, 3], drop_first=True)\n",
    "X = pd.concat([X.iloc[:, :3], State], axis=1)\n",
    "print(X.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R&D Spend  Administration  Marketing Spend  Florida  New York\n",
      "0       True            True             True    False      True\n",
      "1       True            True             True    False     False\n"
     ]
    }
   ],
   "source": [
    "newX = pd.DataFrame([])\n",
    "for j in range(X.shape[1]):\n",
    "    feature = X.iloc[:, j]\n",
    "    feature = feature > feature.mean()\n",
    "    newX = pd.concat([newX, feature], axis=1)\n",
    "print(newX.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0\n",
      "0  False_False_False\n",
      "1    True_True_False\n",
      "2     True_True_True\n",
      "3   False_False_True\n",
      "   Administration  New York  R&D Spend\n",
      "0            True      True       True\n",
      "1            True     False       True\n",
      "2           False     False       True\n",
      "0.004598527569771014\n"
     ]
    }
   ],
   "source": [
    "# Try\n",
    "testresult = iscore(X=newX, y=y, num_initial_draw = 3)\n",
    "print(testresult['Partition'])\n",
    "print(testresult['Set Drawn'].head(3))\n",
    "print(testresult['Influence Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code says that from the covariate matrix *newX* and dependent variable $y$ we are able to randomly draw 3 variables out and compute how predictive they are to $y$. Let us repeat this random sampling many times and compare the result. You can go to the code box above and hit \"ctrl + enter\" and observe different results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
