{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP LEARNING: AUTO-ENCODER\n",
    "\n",
    "I want to express my greatest thanks to this open-source [link](https://blog.keras.io/building-autoencoders-in-keras.html) provided by Keras. This notebook is a direct replica of the content of their blog and it is not-for-profit only. \n",
    "\n",
    "The purpose to create this notebook is the motivation provided by LeCun, Hinton, and Bengio at this [event](https://medium.com/syncedreview/aaai-2020-whats-next-for-deep-learning-hinton-lecun-and-bengio-share-their-visions-e29385dcaed5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Autoencoder?\n",
    "\n",
    "\"Autoencoding\" is a data compression algorithm where the compression and decompression functions are 1) data-specific, 2) lossy, and 3) learned automatically from examples rather than engineered by a human. Additionally, in almost all contexts where the term \"autoencoder\" is used, the compression and decompression functions are implemented with neural networks.\n",
    "\n",
    "1) Autoencoders are data-specific, which means that they will only be able to compress data similar to what they have been trained on. This is different from, say, the MPEG-2 Audio Layer III (MP3) compression algorithm, which only holds assumptions about \"sound\" in general, but not about specific types of sounds. An autoencoder trained on pictures of faces would do a rather poor job of compressing pictures of trees, because the features it would learn would be face-specific.\n",
    "\n",
    "2) Autoencoders are lossy, which means that the decompressed outputs will be degraded compared to the original inputs (similar to MP3 or JPEG compression). This differs from lossless arithmetic compression.\n",
    "\n",
    "3) Autoencoders are learned automatically from data examples, which is a useful property: it means that it is easy to train specialized instances of the algorithm that will perform well on a specific type of input. It doesn't require any new engineering, just appropriate training data.\n",
    "\n",
    "To build an autoencoder, you need three things: an encoding function, a decoding function, and a distance function between the amount of information loss between the compressed representation of your data and the decompressed representation (i.e. a \"loss\" function). The encoder and decoder will be chosen to be parametric functions (typically neural networks), and to be differentiable with respect to the distance function, so the parameters of the encoding/decoding functions can be optimize to minimize the reconstruction loss, using Stochastic Gradient Descent. It's simple! And you don't even need to understand any of these words to start using autoencoders in practice.\n",
    "\n",
    "\n",
    "![image](https://blog.keras.io/img/ae/autoencoder_schema.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are they good at data compression?\n",
    "\n",
    "Usually, not really. In picture compression for instance, it is pretty difficult to train an autoencoder that does a better job than a basic algorithm like JPEG, and typically the only way it can be achieved is by restricting yourself to a very specific type of picture (e.g. one for which JPEG does not do a good job). The fact that autoencoders are data-specific makes them generally impractical for real-world data compression problems: you can only use them on data that is similar to what they were trained on, and making them more general thus requires lots of training data. But future advances might change this, who knows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are autoencoders good for?\n",
    "\n",
    "They are rarely used in practical applications. In 2012 they briefly found an application in greedy layer-wise pretraining for deep convolutional neural networks [1], but this quickly fell out of fashion as we started realizing that better random weight initialization schemes were sufficient for training deep networks from scratch. In 2014, batch normalization [2] started allowing for even deeper networks, and from late 2015 we could train arbitrarily deep networks from scratch using residual learning [3].\n",
    "\n",
    "Today two interesting practical applications of autoencoders are data denoising (which we feature later in this post), and dimensionality reduction for data visualization. With appropriate dimensionality and sparsity constraints, autoencoders can learn data projections that are more interesting than PCA or other basic techniques.\n",
    "\n",
    "For 2D visualization specifically, [t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) (pronounced \"tee-snee\") is probably the best algorithm around, but it typically requires relatively low-dimensional data. So a good strategy for visualizing similarity relationships in high-dimensional data is to start by using an autoencoder to compress your data into a low-dimensional space (e.g. 32 dimensional), then use t-SNE for mapping the compressed data to a 2D plane. Note that a nice parametric implementation of t-SNE in Keras was developed by Kyle McDonald and is available on [Github](https://github.com/kylemcdonald/Parametric-t-SNE/blob/master/Parametric%20t-SNE%20(Keras).ipynb). Otherwise [scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) also has a simple and practical implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So what's the big deal with autoencoders?\n",
    "\n",
    "Their main claim to fame comes from being featured in many introductory machine learning classes available online. As a result, a lot of newcomers to the field absolutely love autoencoders and can't get enough of them. This is the reason why this tutorial exists!\n",
    "\n",
    "Otherwise, one reason why they have attracted so much research and attention is because they have long been thought to be a potential avenue for solving the problem of unsupervised learning, i.e. the learning of useful representations without the need for labels. Then again, autoencoders are not a true unsupervised learning technique (which would imply a different learning process altogether), they are a self-supervised technique, a specific instance of supervised learning where the targets are generated from the input data. In order to get self-supervised models to learn interesting features, you have to come up with an interesting synthetic target and loss function, and that's where problems arise: merely learning to reconstruct your input in minute detail might not be the right choice here. At this point there is significant evidence that focusing on the reconstruction of a picture at the pixel level, for instance, is not conductive to learning interesting, abstract features of the kind that label-supervized learning induces (where targets are fairly abstract concepts \"invented\" by humans such as \"dog\", \"car\"...). In fact, one may argue that the best features in this regard are those that are the worst at exact input reconstruction while achieving high performance on the main task that you are interested in (classification, localization, etc).\n",
    "\n",
    "In self-supervized learning applied to vision, a potentially fruitful alternative to autoencoder-style input reconstruction is the use of toy tasks such as jigsaw puzzle solving, or detail-context matching (being able to match high-resolution but small patches of pictures with low-resolution versions of the pictures they are extracted from). The following paper investigates jigsaw puzzle solving and makes for a very interesting read: Noroozi and Favaro (2016) [Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles](http://arxiv.org/abs/1603.09246). Such tasks are providing the model with built-in assumptions about the input data which are missing in traditional autoencoders, such as \"visual macro-structure matters more than pixel-level details\".\n",
    "\n",
    "![image](https://blog.keras.io/img/ae/jigsaw-puzzle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our inputs are images, it makes sense to use convolutional neural networks (convnets) as encoders and decoders. In practical settings, autoencoders applied to images are always convolutional autoencoders --they simply perform much better.\n",
    "\n",
    "Let's implement one. The encoder will consist in a stack of *Conv2D* and *MaxPooling2D* layers (max pooling being used for spatial down-sampling), while the decoder will consist in a stack of *Conv2D* and *UpSampling2D* layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train it, we will use the original MNIST digits with shape (samples, 3, 28, 28), and we will just normalize pixel values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=/tmp/autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.2147 - val_loss: 0.1587\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1512 - val_loss: 0.1379\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1364 - val_loss: 0.1297\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1294 - val_loss: 0.1260\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1246 - val_loss: 0.1194\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1209 - val_loss: 0.1179\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1185 - val_loss: 0.1171\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1166 - val_loss: 0.1129\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1147 - val_loss: 0.1105\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1132 - val_loss: 0.1120\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1122 - val_loss: 0.1071\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 75s 1ms/step - loss: 0.1114 - val_loss: 0.1080\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1104 - val_loss: 0.1080\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1095 - val_loss: 0.1081\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1088 - val_loss: 0.1074\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1082 - val_loss: 0.1085\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1075 - val_loss: 0.1032\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1069 - val_loss: 0.1056\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1063 - val_loss: 0.1033\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1061 - val_loss: 0.1049\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1054 - val_loss: 0.1037\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1047 - val_loss: 0.1018\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1046 - val_loss: 0.1011\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1041 - val_loss: 0.1045\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1038 - val_loss: 0.1006\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1035 - val_loss: 0.1023\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1030 - val_loss: 0.1022\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1030 - val_loss: 0.0991\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1026 - val_loss: 0.0995\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1022 - val_loss: 0.1000\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1022 - val_loss: 0.1013\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1016 - val_loss: 0.0990\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1014 - val_loss: 0.1021\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1011 - val_loss: 0.1001\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 75s 1ms/step - loss: 0.1009 - val_loss: 0.0996\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1008 - val_loss: 0.1024\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1006 - val_loss: 0.0997\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1004 - val_loss: 0.1004\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1003 - val_loss: 0.0967\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.0999 - val_loss: 0.1006\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.1000 - val_loss: 0.0971\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.0999 - val_loss: 0.1015\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.0998 - val_loss: 0.0997\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.0996 - val_loss: 0.0996\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.0995 - val_loss: 0.0995\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.0990 - val_loss: 0.0991\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.0989 - val_loss: 0.0974\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.0988 - val_loss: 0.0993\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 76s 1ms/step - loss: 0.0988 - val_loss: 0.0997\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.0989 - val_loss: 0.0961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc95970e400>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test) )\n",
    "# callbacks=[TensorBoard(log_dir='/tmp/autoencoder')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_imgs.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigation ends here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
